{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/workspace/Konan/simulation/load_4_sim'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Data science libraries\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Pytorch\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch import optim\n",
    "from torch.nn.modules.loss import CrossEntropyLoss\n",
    "\n",
    "# Others\n",
    "from IPython.core.debugger import set_trace\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helper import download, matfile_to_df ,get_df_all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path('.')\n",
    "DATA_PATH = Path(\"/home/workspace/Konan/simulation/load_4_sim/\")\n",
    "DE_path = DATA_PATH "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "whole_file = matfile_to_df(DE_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>X_sim_with_noise</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/B5...</td>\n",
       "      <td>[[-0.8998710794443441], [5.3208332220437455], ...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/IO...</td>\n",
       "      <td>[[4.507048237633715], [1.9339607886959036], [9...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/OB...</td>\n",
       "      <td>[[3.6636506243245646], [-0.660161235695166], [...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/N5...</td>\n",
       "      <td>[[-0.005162664806454463], [0.1806704230899435]...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/I5...</td>\n",
       "      <td>[[5.934431288982745], [-0.9059397773063107], [...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/IB...</td>\n",
       "      <td>[[-0.4477840422163923], [-2.4089571199504825],...</td>\n",
       "      <td>B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>/home/workspace/Konan/simulation/load_4_sim/O5...</td>\n",
       "      <td>[[-0.4030903771882294], [3.0864120894336566], ...</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename  \\\n",
       "0  /home/workspace/Konan/simulation/load_4_sim/B5...   \n",
       "1  /home/workspace/Konan/simulation/load_4_sim/IO...   \n",
       "2  /home/workspace/Konan/simulation/load_4_sim/OB...   \n",
       "3  /home/workspace/Konan/simulation/load_4_sim/N5...   \n",
       "4  /home/workspace/Konan/simulation/load_4_sim/I5...   \n",
       "5  /home/workspace/Konan/simulation/load_4_sim/IB...   \n",
       "6  /home/workspace/Konan/simulation/load_4_sim/O5...   \n",
       "\n",
       "                                    X_sim_with_noise label  \n",
       "0  [[-0.8998710794443441], [5.3208332220437455], ...     B  \n",
       "1  [[4.507048237633715], [1.9339607886959036], [9...  None  \n",
       "2  [[3.6636506243245646], [-0.660161235695166], [...     B  \n",
       "3  [[-0.005162664806454463], [0.1806704230899435]...  None  \n",
       "4  [[5.934431288982745], [-0.9059397773063107], [...  None  \n",
       "5  [[-0.4477840422163923], [-2.4089571199504825],...     B  \n",
       "6  [[-0.4030903771882294], [3.0864120894336566], ...  None  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whole_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ball = whole_file.iloc[0,:][1]\n",
    "in_out = whole_file.iloc[1,:][1]\n",
    "out_ball = whole_file.iloc[2,:][1]\n",
    "normal = whole_file.iloc[3,:][1]\n",
    "inner = whole_file.iloc[4,:][1]\n",
    "in_ball = whole_file.iloc[5,:][1]\n",
    "outer = whole_file.iloc[6,:][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = np.zeros((1, 2048))\n",
    "data_ball = np.zeros((1, 2048))\n",
    "data_inner = np.zeros((1, 2048))\n",
    "data_outer = np.zeros((1, 2048))\n",
    "data_in_out = np.zeros((1, 2048))\n",
    "data_out_ball = np.zeros((1, 2048))\n",
    "data_ball_in = np.zeros((1, 2048))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_ball = np.concatenate((data_ball, np.expand_dims(ball[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_inner = np.concatenate((data_inner, np.expand_dims(inner[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_outer = np.concatenate((data_outer, np.expand_dims(outer[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_normal = np.concatenate((data_normal, np.expand_dims(normal[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_ball_in = np.concatenate((data_ball_in, np.expand_dims(in_ball[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_out_ball = np.concatenate((data_out_ball, np.expand_dims(out_ball[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1500):\n",
    "    try:\n",
    "        data_in_out = np.concatenate((data_in_out, np.expand_dims(in_out[300 * i : 2048 + 300 * i, 0], axis = 0)))\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1501, 2048)\n",
      "(1501, 2048)\n",
      "(1501, 2048)\n",
      "(1501, 2048)\n",
      "(1501, 2048)\n",
      "(1501, 2048)\n",
      "(1501, 2048)\n"
     ]
    }
   ],
   "source": [
    "print(data_ball.shape)\n",
    "print(data_normal.shape)\n",
    "print(data_inner.shape)\n",
    "print(data_outer.shape)\n",
    "print(data_in_out.shape)\n",
    "print(data_out_ball.shape)\n",
    "print(data_ball_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_normal = np.delete(data_normal, 0, 0)\n",
    "data_ball = np.delete(data_ball, 0, 0)\n",
    "data_inner = np.delete(data_inner, 0, 0)\n",
    "data_outer = np.delete(data_outer, 0, 0)\n",
    "data_ball_in = np.delete(data_ball_in, 0, 0)\n",
    "data_out_ball = np.delete(data_out_ball, 0, 0)\n",
    "data_in_out = np.delete(data_in_out, 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/workspace/Konan/simulation/save/sim_nomal.npy', data_normal)\n",
    "np.save('/home/workspace/Konan/simulation/save/sim_ball.npy', data_ball)\n",
    "np.save('/home/workspace/Konan/simulation/save/sim_inner.npy', data_inner)\n",
    "np.save('/home/workspace/Konan/simulation/save/sim_outer.npy', data_outer)\n",
    "np.save('/home/workspace/Konan/simulation/save/sim_out_ball.npy', data_out_ball)\n",
    "np.save('/home/workspace/Konan/simulation/save/sim_ball_in.npy', data_ball_in)\n",
    "np.save('/home/workspace/Konan/simulation/save/sim_in_out.npy', data_in_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "nor = np.full((1500,1), 0)\n",
    "ball = np.full((1500,1), 1)\n",
    "inner = np.full((1500,1), 2)\n",
    "outer = np.full((1500,1), 3)\n",
    "out_ball = np.full((250,1), 4)\n",
    "ball_in = np.full((250,1), 5)\n",
    "in_out = np.full((250,1), 6)\n",
    "data = np.concatenate((data_normal, data_ball, data_inner, data_outer), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = np.concatenate((nor, ball, inner, outer), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((label, data), axis = 1)\n",
    "df_all = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/workspace/Konan/simulation/save/whole.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole set 1500\n",
      "test_num 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data_x = data[:,1:]\n",
    "data_y = data[:,0]\n",
    "\n",
    "c1 = np.random.choice(np.where(df_all[:,0] == 0)[0], int(np.where(df_all[:,0] == 0)[0].shape[0]), replace=False)\n",
    "c2 = np.random.choice(np.where(df_all[:,0] == 1)[0], int(np.where(df_all[:,0] == 1)[0].shape[0]), replace=False)\n",
    "c3 = np.random.choice(np.where(df_all[:,0] == 2)[0], int(np.where(df_all[:,0] == 2)[0].shape[0]), replace=False)\n",
    "c4 = np.random.choice(np.where(df_all[:,0] == 3)[0], int(np.where(df_all[:,0] == 3)[0].shape[0]), replace=False)\n",
    "num = min(len(c1),len(c3),len(c4))\n",
    "print('whole set',num)\n",
    "\n",
    "d1 = c1[:num]\n",
    "d2 = c2[:num]\n",
    "d3 = c3[:num]\n",
    "d4 = c4[:num]\n",
    "\n",
    "set = np.concatenate((d1, d2, d3, d4), axis = 0)\n",
    "\n",
    "t_1 = d1[:150]\n",
    "t_2 = d2[:150]\n",
    "t_3 = d3[:150]\n",
    "t_4 = d4[:150]\n",
    "print('test_num', num // 10)\n",
    "test_num = np.concatenate((t_1, t_2, t_3, t_4), axis = 0)\n",
    "\n",
    "test_x = data_x[test_num, :]\n",
    "sc_te = StandardScaler()\n",
    "\n",
    "test_x = test_x.T\n",
    "test_x = sc_te.fit_transform(test_x)\n",
    "test_x = test_x.T\n",
    "test_y = data_y[test_num]\n",
    "test_y = np.expand_dims(test_y, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = np.setdiff1d(set, test_num)\n",
    "test_data = np.concatenate((test_y, test_x), axis = 1)\n",
    "np.save('/home/workspace/dataset/test_data/konan_sim/test_set.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole set 1350\n",
      "test_num 135\n"
     ]
    }
   ],
   "source": [
    "df_all = data[train_set, :]\n",
    "data_x = df_all[:,1:]\n",
    "data_y = df_all[:,0]\n",
    "\n",
    "c1 = np.random.choice(np.where(df_all[:,0] == 0)[0], int(np.where(df_all[:,0] == 0)[0].shape[0]), replace=False)\n",
    "c2 = np.random.choice(np.where(df_all[:,0] == 1)[0], int(np.where(df_all[:,0] == 1)[0].shape[0]), replace=False)\n",
    "c3 = np.random.choice(np.where(df_all[:,0] == 2)[0], int(np.where(df_all[:,0] == 2)[0].shape[0]), replace=False)\n",
    "c4 = np.random.choice(np.where(df_all[:,0] == 3)[0], int(np.where(df_all[:,0] == 3)[0].shape[0]), replace=False)\n",
    "num = min(len(c1),len(c3),len(c4))\n",
    "print('whole set',num)\n",
    "\n",
    "d1 = c1[:num]\n",
    "d2 = c2[:num]\n",
    "d3 = c3[:num]\n",
    "d4 = c4[:num]\n",
    "\n",
    "set = np.concatenate((d1, d2, d3, d4), axis = 0)\n",
    "\n",
    "t_1 = d1[:150]\n",
    "t_2 = d2[:150]\n",
    "t_3 = d3[:150]\n",
    "t_4 = d4[:150]\n",
    "print('test_num', num // 10)\n",
    "test_num = np.concatenate((t_1, t_2, t_3, t_4), axis = 0)\n",
    "\n",
    "test_x = data_x[test_num, :]\n",
    "sc_te = StandardScaler()\n",
    "\n",
    "test_x = test_x.T\n",
    "test_x = sc_te.fit_transform(test_x)\n",
    "test_x = test_x.T\n",
    "test_y = data_y[test_num]\n",
    "test_y = np.expand_dims(test_y, axis = 1)\n",
    "\n",
    "train_set =  np.setdiff1d(set, test_num)\n",
    "test_data = np.concatenate((test_y, test_x), axis = 1)\n",
    "np.save('/home/workspace/dataset/valid_data/konan_sim/valid_set.npy', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('/home/workspace/dataset/train_data/konan_sim/train_whole.npy', df_all[train_set])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    \n",
    "def make_dataset(train, labeled_len, unlabeled_len):\n",
    "    data_x = train[:,1:]\n",
    "    data_y = train[:,0]\n",
    "    \n",
    "    c1 = np.random.choice(np.where(train[:,0] == 0)[0], int(np.where(train[:,0] == 0)[0].shape[0]), replace=False)\n",
    "    c2 = np.random.choice(np.where(train[:,0] == 1)[0], int(np.where(train[:,0] == 1)[0].shape[0]), replace=False)\n",
    "    c3 = np.random.choice(np.where(train[:,0] == 2)[0], int(np.where(train[:,0] == 2)[0].shape[0]), replace=False)\n",
    "    c4 = np.random.choice(np.where(train[:,0] == 3)[0], int(np.where(train[:,0] == 3)[0].shape[0]), replace=False)\n",
    "\n",
    "    num = min(len(c1),len(c2),len(c3),len(c4))\n",
    "    print('whole set',num)\n",
    "\n",
    "    d1 = np.random.choice(c1, num, replace = False)\n",
    "    d2 = np.random.choice(c2, num, replace = False)\n",
    "    d3 = np.random.choice(c3, num, replace = False)\n",
    "    d4 = np.random.choice(c4, num, replace = False)\n",
    "\n",
    "    set = np.concatenate((d1,d2,d3,d4), axis = 0)\n",
    "\n",
    "    l_1 = np.random.choice(d1, labeled_len, replace = False)\n",
    "    l_2 = np.random.choice(d2, labeled_len, replace = False)\n",
    "    l_3 = np.random.choice(d3, labeled_len, replace = False)\n",
    "    l_4 = np.random.choice(d4, labeled_len, replace = False)\n",
    "    \n",
    "    labeled_num = np.concatenate((l_1, l_2, l_3, l_4), axis = 0)\n",
    "    \n",
    "    sc_tr = StandardScaler()\n",
    "\n",
    "    \n",
    "    l_train = data_x[labeled_num, :]\n",
    "    l_train = l_train.T\n",
    "    l_train = sc_tr.fit_transform(l_train)\n",
    "    l_train = l_train.T\n",
    "    train_y = data_y[labeled_num]\n",
    "    train_y = np.expand_dims(train_y, axis = 1)\n",
    "    \n",
    "    labeled_data = np.concatenate((train_y, l_train), axis = 1)\n",
    "    \n",
    "    ###############################################################################################################\n",
    "    u_1 = np.random.choice(np.setdiff1d(d1, l_1), unlabeled_len, replace = False)\n",
    "    u_2 = np.random.choice(np.setdiff1d(d2, l_2), unlabeled_len, replace = False)\n",
    "    u_3 = np.random.choice(np.setdiff1d(d3, l_3), unlabeled_len, replace = False)\n",
    "    u_4 = np.random.choice(np.setdiff1d(d4, l_4), unlabeled_len, replace = False)\n",
    "\n",
    "    unlabeled_num = np.concatenate((u_1, u_2, u_3, u_4), axis = 0)\n",
    "\n",
    "    sc_tru = StandardScaler()\n",
    " \n",
    "    u_train = data_x[unlabeled_num, :]\n",
    "    u_train = u_train.T\n",
    "    u_train = sc_tru.fit_transform(u_train)\n",
    "    u_train = u_train.T\n",
    "    u_y = data_y[unlabeled_num]\n",
    "    u_y = np.expand_dims(u_y, axis = 1)\n",
    "\n",
    "    unlabeled_data = np.concatenate((u_y, u_train),axis = 1)\n",
    "\n",
    "    np.save(f'/home/workspace/dataset/train_data/konan_sim/labeled_data.npy', labeled_data)\n",
    "    np.save(f'/home/workspace/dataset/train_data/konan_sim/unlabeled_{unlabeled_len}.npy', unlabeled_data)\n",
    "\n",
    "    return labeled_data, unlabeled_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whole set 1200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.        , -0.70856574, -0.69135535, ...,  0.80489879,\n",
       "          1.85428802,  0.9029725 ],\n",
       "        [ 0.        ,  0.50556925, -0.07641815, ..., -0.15163911,\n",
       "         -0.66552759, -1.74134657],\n",
       "        [ 0.        , -1.51301926, -1.35729598, ..., -1.41731248,\n",
       "         -0.97909857, -1.9638829 ],\n",
       "        ...,\n",
       "        [ 3.        , -1.43605949, -0.39279957, ...,  1.11678708,\n",
       "          0.21059099, -0.5715085 ],\n",
       "        [ 3.        , -0.77783568, -0.03674116, ..., -0.53494876,\n",
       "         -1.57093799, -0.13816866],\n",
       "        [ 3.        ,  0.39768081,  1.77770603, ...,  0.08684158,\n",
       "          0.7111983 ,  0.66885661]]),\n",
       " array([[ 0.        ,  0.91110356,  0.7615176 , ..., -0.18926179,\n",
       "          0.9359498 ,  0.2301338 ],\n",
       "        [ 0.        , -1.55408612, -1.4695967 , ..., -2.2622454 ,\n",
       "         -1.79750532, -0.6348338 ],\n",
       "        [ 0.        ,  0.31270404, -1.58908642, ..., -0.15186257,\n",
       "          0.59292222, -0.73851881],\n",
       "        ...,\n",
       "        [ 3.        ,  0.07814253,  0.81853237, ..., -0.20824981,\n",
       "         -1.08222015, -0.50074037],\n",
       "        [ 3.        ,  0.03921658, -0.12241269, ...,  0.96345617,\n",
       "         -0.84965309, -0.15193306],\n",
       "        [ 3.        ,  0.65838944,  1.99010833, ..., -0.61027775,\n",
       "         -0.31819464,  0.26447767]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_dataset(np.load('/home/workspace/dataset/train_data/konan_sim/train_whole.npy'), 3, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4800, 2049)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.load('/home/workspace/dataset/train_data/konan_sim/train_whole.npy')\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f33d7ee5ac72b11c0805f75ad33fa070254e40c717e445ff508a53f9b1705a88"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
